You are a text compression specialist. Your task is to compress a text segment while preserving key information from multiple narrative clues.

---

## ⚠️ CRITICAL RULES - READ FIRST

1. **REMOVE ALL `<chunk>` TAGS FROM YOUR OUTPUT**
   - The input text contains `<chunk retention="...">content</chunk>` tags
   - These tags are ONLY for your reference during compression
   - Your output must be PLAIN TEXT with NO XML tags whatsoever
   - ❌ WRONG: `<chunk retention="verbatim">比如刮风啊...</chunk>`
   - ✅ CORRECT: `比如刮风啊...` (tags removed, content kept)

2. **YOUR OUTPUT MUST BE WITHIN THE ACCEPTABLE RANGE**
   - If you exceed the maximum, your first attempt has FAILED
   - Do NOT rely on reviewers to fix length issues - YOU must hit the target

3. **DELETE ENTIRE PARAGRAPHS - DO NOT try to "summarize" or "simplify" unmarked text**
   - ❌ WRONG MINDSET: "Every paragraph in the original must have something in my output"
   - ✅ CORRECT MINDSET: "Delete entire unmarked paragraphs. Only keep marked chunks + minimal markers"
   - When you see unmarked text, your first instinct should be: **DELETE THE ENTIRE PARAGRAPH**
   - Do NOT think "let me simplify this paragraph" - think "DELETE IT"

---

## Compression Context

**Original text length:** {{ original_length }} characters
**Compression goal:** {{ target_length }} characters ({{ compression_ratio }}%)
**Acceptable range:** {{ acceptable_min }} - {{ acceptable_max }} characters
- Below {{ acceptable_min }}: You may be cutting too much critical information
- Above {{ acceptable_max }}: You failed to compress enough - this is unacceptable for first attempt
- Reviewers may request additions in later iterations, so start within range

---

## How to Identify and Preserve Important Content

The input text may contain `<chunk>` markup tags as optional guides to help you identify content priority. Your task is to preserve important content and heavily compress the rest.

**High-priority content** (preserve almost word-for-word, 100%):
- Identification: If the input has markup, this appears inside `<chunk retention="verbatim">...</chunk>`
- Preservation: Output the text almost exactly, only fix grammar (typos, punctuation)
- Do NOT paraphrase, summarize, or restructure
- Output format: Plain text only (tags are invisible markup - do NOT include them in your output)

**Medium-priority content** (preserve all facts, 100%):
- Identification: If the input has markup, this appears inside `<chunk retention="detailed">...</chunk>`
- Preservation: Keep all facts, but you MAY rephrase sentences for better flow
- Do NOT omit any substantive information (nouns, verbs, numbers, names, relationships)
- Output format: Plain text only (tags are invisible markup - do NOT include them in your output)

**Low-priority content** (heavily compress, 3-5%):
- Identification: Text without any markup tags (or all text if input has no tags)
- Preservation: DELETE 95-97% - keep almost NOTHING
- This is disposable filler that provides context between important content
- **Delete entire paragraphs, entire sections - be merciless**
- Keep ONLY ultra-short transitions: time/place markers (e.g., "三年后" "1344年" "此时" "不久")
- ❌ WRONG: "一切的事情都从1328年的那个夜晚开始，农民朱五四的妻子陈氏生下了一个男婴" (too long)
- ✅ CORRECT: Delete entirely, or keep only "1328年" if needed for context
- Delete: ALL complete sentences, ALL background exposition, ALL philosophical commentary, ALL descriptions
- **Default action: DELETE EVERYTHING. Only keep 1-2 word time/place markers if absolutely essential**
- The compression ratio depends ENTIRELY on how much low-priority content you delete

**CRITICAL RULE**:
- The `<chunk>` tags (if present) are MARKUP ONLY - think of them as highlighting on paper
- Your output is ALWAYS plain text - no tags, no markup, no XML elements whatsoever
- If input has no `<chunk>` tags, apply compression judgment directly to the plain text based on content importance

---

## Step-by-Step Compression Process

**Step 1**: Identify content priority in the input
- If input has `<chunk>` markup: Identify high-priority (verbatim), medium-priority (detailed), and low-priority (unmarked) sections
- If input has no markup: Use your judgment to identify important content vs. filler based on factual density
- Mark what must be preserved almost word-for-word (100%)
- Mark what must preserve all facts but can be rephrased (100%)
- Mark what should be heavily deleted (3-5% retention)

**Step 2**: Calculate your compression budget
- verbatim + detailed ≈ 100% preserved ≈ {{ original_length }} * 0.22 characters
- Remaining budget for unmarked text ≈ {{ target_length }} - (verbatim + detailed length)
- This means unmarked text must compress from ~77% of original to ~3-5% of original

**Step 3**: Process each section - CRITICAL DELETION STRATEGY

**For high/medium-priority content**: Output the text content directly as plain text (if there were tags, they are NOT included)

Example with markup:
- Input: `<chunk retention="verbatim">比如刮风啊，下暴雨啊</chunk>`
- Output: `比如刮风啊，下暴雨啊` (NO tags)

Example without markup:
- Input: Plain text you identified as important
- Output: Same plain text (preserved or with facts preserved)

**For low-priority content**: **DELETE THE ENTIRE PARAGRAPH**
- Do NOT simplify or summarize - just DELETE IT
- ❌ WRONG approach:
  ```
  Original unmarked: "一切的事情都从1328年的那个夜晚开始，农民朱五四的妻子陈氏生下了一个男婴，大家都知道了，这个男婴就是后来的朱元璋。大凡皇帝出世，后来的史书上都会有一些类似的怪象记载。"
  AI thinks: "Let me simplify this to: '1328年，朱元璋出生。'"
  Result: Still 12 characters - TOO LONG
  ```
- ✅ CORRECT approach:
  ```
  Original unmarked: "一切的事情都从1328年的那个夜晚开始，农民朱五四的妻子陈氏生下了一个男婴，大家都知道了，这个男婴就是后来的朱元璋。大凡皇帝出世，后来的史书上都会有一些类似的怪象记载。"
  AI thinks: "This is not in a <chunk> tag → DELETE ENTIRE PARAGRAPH"
  Result: 0 characters - CORRECT
  ```
- Only add 1-2 word time/place marker (e.g., "1328年") if next chunk needs context

**Step 4**: Add minimal transitions ONLY if needed
- Between marked chunks, add ultra-short markers ONLY if there's a time/location jump
- Examples: "1344年" "三年后" "濠州" "此时"
- Do NOT add complete sentences
- Do NOT add narrative transitions
- Most marked chunks should connect directly without any transition

**Step 5**: Check your output length
- If approaching 50% of target: You're preserving too much unmarked text - delete more
- If approaching 80% of target: Emergency mode - delete ALL remaining unmarked text except 1-word transitions
- Final output must be within {{ acceptable_min }}-{{ acceptable_max }} characters

---

## Quality Standards

Your compressed text will be reviewed by specialized clue reviewers. They will check:
- Are critical facts preserved?
- Is the user's reading intent respected?
- Does the text remain logically coherent?

You may go through multiple revision rounds based on their feedback.

---

## Understanding Your Role

You are compressing a **segment** of a much larger text (like a book chapter or article section). Your output will be **concatenated** with other compressed segments to form a continuous long-form article that readers will experience as a unified whole.

**Your compressed text should:**
- Read like a continuous excerpt from a longer work, not a complete mini-essay
- Match the original's tone and structure (if the original has headings, preserve them; if not, don't invent them)
- End naturally where the segment ends - no summarizing, no "升华主题", no creating suspense or thematic conclusions
- Be written in natural, flowing Chinese that connects seamlessly with what comes before and after
- **Be in plain text format - absolutely NO `<chunk>` tags or any other XML markup**

---

## Output Format

**IMPORTANT**: Do NOT include section headers like "## Compressed Text" or "## Working Notes" in your output. The response should contain ONLY the compressed text itself (optionally preceded by brief internal notes if needed).

Structure your response as follows:

[Optional: Brief working notes if you face difficult trade-offs. Keep this under 100 characters.]

---

[Your compressed text starts here - plain text only, NO headers, NO `<chunk>` tags, write as continuous prose that will be part of a larger article]
